{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  9 21:55:13 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.07              Driver Version: 546.12       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070        On  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   44C    P5              21W / 200W |    968MiB / 12282MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository: 'deb https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu/ jammy main'\n",
      "Description:\n",
      "Backport of FFmpeg 4 and associated libraries. Now includes AOM/AV1 support!\n",
      "\n",
      "FDK AAC is not compatible with GPL and FFmpeg can't be redistributed with it included. Please don't ask for it to be added to this public PPA.\n",
      "\n",
      "---\n",
      "\n",
      "PPA supporters:\n",
      "\n",
      "BigBlueButton (https://bigbluebutton.org)\n",
      "\n",
      "---\n",
      "\n",
      "Donate to FFMPEG: https://ffmpeg.org/donations.html\n",
      "Donate to Debian: https://www.debian.org/donations\n",
      "Donate to this PPA: https://ko-fi.com/jonathonf\n",
      "More info: https://launchpad.net/~jonathonf/+archive/ubuntu/ffmpeg-4\n",
      "Adding repository.\n",
      "Found existing deb entry in /etc/apt/sources.list.d/jonathonf-ubuntu-ffmpeg-4-jammy.list\n",
      "Adding deb entry to /etc/apt/sources.list.d/jonathonf-ubuntu-ffmpeg-4-jammy.list\n",
      "Found existing deb-src entry in /etc/apt/sources.list.d/jonathonf-ubuntu-ffmpeg-4-jammy.list\n",
      "Adding disabled deb-src entry to /etc/apt/sources.list.d/jonathonf-ubuntu-ffmpeg-4-jammy.list\n",
      "Adding key to /etc/apt/trusted.gpg.d/jonathonf-ubuntu-ffmpeg-4.gpg with fingerprint 4AB0F789CBA31744CC7DA76A8CF63AD3F06FC659\n",
      "Get:1 file:/var/cuda-repo-wsl-ubuntu-11-8-local  InRelease [1575 B]\n",
      "Get:1 file:/var/cuda-repo-wsl-ubuntu-11-8-local  InRelease [1575 B]\n",
      "Get:2 file:/var/cuda-repo-wsl-ubuntu-12-3-local  InRelease [1572 B]\n",
      "Get:2 file:/var/cuda-repo-wsl-ubuntu-12-3-local  InRelease [1572 B]\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease               \n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease               \n",
      "Ign:7 https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy InRelease\n",
      "Err:8 https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy Release\n",
      "  404  Not Found [IP: 185.125.190.80 443]\n",
      "Reading package lists... Done\n",
      "E: The repository 'https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy Release' does not have a Release file.\n",
      "N: Updating from such a repository can't be done securely, and is therefore disabled by default.\n",
      "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
      "Get:1 file:/var/cuda-repo-wsl-ubuntu-11-8-local  InRelease [1575 B]\n",
      "Get:2 file:/var/cuda-repo-wsl-ubuntu-12-3-local  InRelease [1572 B]\n",
      "Get:1 file:/var/cuda-repo-wsl-ubuntu-11-8-local  InRelease [1575 B]\n",
      "Get:2 file:/var/cuda-repo-wsl-ubuntu-12-3-local  InRelease [1572 B]\n",
      "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Ign:4 https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy InRelease\n",
      "Err:5 https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy Release\n",
      "  404  Not Found [IP: 185.125.190.80 443]\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease0m\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Reading package lists... Done\n",
      "\u001b[1;31mE: \u001b[0mThe repository 'https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy Release' does not have a Release file.\u001b[0m\n",
      "\u001b[33mN: \u001b[0mUpdating from such a repository can't be done securely, and is therefore disabled by default.\u001b[0m\n",
      "\u001b[33mN: \u001b[0mSee apt-secure(8) manpage for repository creation and user configuration details.\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n",
    "!apt update\n",
    "!apt install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (23.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: transformers in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (4.36.0.dev0)\n",
      "Requirement already satisfied: accelerate in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: soundfile in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: librosa in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (0.10.1)\n",
      "Requirement already satisfied: evaluate in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: jiwer in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (3.0.3)\n",
      "Requirement already satisfied: tensorboard==2.8 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: gradio in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (4.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (1.59.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (3.20.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (68.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from tensorboard==2.8) (0.38.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: pandas in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: psutil in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from accelerate) (2.1.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (0.57.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (4.8.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: responses<0.19 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from evaluate) (0.13.3)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from jiwer) (8.1.7)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from jiwer) (3.5.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (4.2.2)\n",
      "Requirement already satisfied: fastapi in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (0.104.1)\n",
      "Requirement already satisfied: ffmpy in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.7.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (0.7.1)\n",
      "Requirement already satisfied: httpx in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (0.25.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (3.9.10)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (2.5.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio) (0.24.0.post1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from gradio-client==0.7.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: entrypoints in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: pycparser in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.8) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.8) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.8) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8) (1.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.40.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from pooch>=1.0->librosa) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.14.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.8) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.8) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.8) (2023.7.22)\n",
      "Requirement already satisfied: six in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from responses<0.19->evaluate) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: sympy in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
      "Requirement already satisfied: h11>=0.8 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from fastapi->gradio) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore==1.* in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from httpx->gradio) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.0.4)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.8) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8) (3.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.15.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade datasets transformers accelerate soundfile librosa evaluate jiwer tensorboard==2.8 gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialise the data collator we've just defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Romanian\", task=\"transcribe\")\n",
    "\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Romanian\", task=\"transcribe\")\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "We'll use the word error rate (WER) metric, the 'de-facto' metric for assessing \n",
    "ASR systems. For more information, refer to the WER [docs](https://huggingface.co/metrics/wer). We'll load the WER metric from 🤗 Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then simply have to define a function that takes our model \n",
    "predictions and returns the WER metric. This function, called\n",
    "`compute_metrics`, first replaces `-100` with the `pad_token_id`\n",
    "in the `label_ids` (undoing the step we applied in the \n",
    "data collator to ignore padded tokens correctly in the loss).\n",
    "It then decodes the predicted and label ids to strings. Finally,\n",
    "it computes the WER between the predictions and reference labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a Pre-Trained Checkpoint\n",
    "\n",
    "Now let's load the pre-trained Whisper `small` checkpoint. Again, this \n",
    "is trivial through use of 🤗 Transformers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Romanian\", task=\"transcribe\")\n",
    "\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Romanian\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override generation arguments - no tokens are forced as decoder outputs (see [`forced_decoder_ids`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.forced_decoder_ids)), no tokens are suppressed during generation (see [`suppress_tokens`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.suppress_tokens)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, we define all the parameters related to training. For more detail on the training arguments, refer to the Seq2SeqTrainingArguments [docs](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict.load_from_disk(\"/content/gdrive/My Drive/common_voice/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    output_dir=\"/content/gdrive/My Drive/whisper_romanian\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=5e-6,\n",
    "    seed=42,\n",
    "    optim='adamw_torch',\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.999,\n",
    "    adam_epsilon=1e-08,\n",
    "    lr_scheduler_type='constant_with_warmup',\n",
    "    warmup_steps=50,\n",
    "    max_steps=1500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=250,\n",
    "    save_total_limit=3,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    eval_steps=250,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if one does not want to upload the model checkpoints to the Hub, \n",
    "set `push_to_hub=False`.\n",
    "\n",
    "We can forward the training arguments to the 🤗 Trainer along with our model,\n",
    "dataset, data collator and `compute_metrics` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll save the processor object once before starting training. Since the processor is not trainable, it won't change over the course of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Training will take approximately 5-10 hours depending on your GPU or the one \n",
    "allocated to this Google Colab. If using this Google Colab directly to \n",
    "fine-tune a Whisper model, you should make sure that training isn't \n",
    "interrupted due to inactivity. A simple workaround to prevent this is \n",
    "to paste the following code into the console of this tab (_right mouse click_ \n",
    "-> _inspect_ -> _Console tab_ -> _insert code_).\n",
    "\n",
    "\n",
    "```javascript\n",
    "function ConnectButton(){\n",
    "    console.log(\"Connect pushed\"); \n",
    "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
    "}\n",
    "setInterval(ConnectButton, 60000);\n",
    "```\n",
    "\n",
    "\n",
    "The peak GPU memory for the given training configuration is approximately 15.8GB. \n",
    "Depending on the GPU allocated to the Google Colab, it is possible that you will encounter a CUDA `\"out-of-memory\"` error when you launch training. \n",
    "In this case, you can reduce the `per_device_train_batch_size` incrementally by factors of 2 \n",
    "and employ [`gradient_accumulation_steps`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments.gradient_accumulation_steps)\n",
    "to compensate.\n",
    "\n",
    "To launch training, simply execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_features', 'labels'],\n",
       "        num_rows: 8890\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_features', 'labels'],\n",
       "        num_rows: 3859\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 4:02:14, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.233592</td>\n",
       "      <td>24.417521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.236113</td>\n",
       "      <td>25.062729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.247866</td>\n",
       "      <td>27.553947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.249090</td>\n",
       "      <td>27.317370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.253168</td>\n",
       "      <td>21.123378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.255652</td>\n",
       "      <td>23.876264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/ID2223_lab2/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.01020404906074206, metrics={'train_runtime': 14538.6303, 'train_samples_per_second': 1.651, 'train_steps_per_second': 0.103, 'total_flos': 6.92258658287616e+18, 'train_loss': 0.01020404906074206, 'epoch': 2.7})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"mozilla-foundation/common_voice_11_0\",\n",
    "    \"dataset\": \"Romanian voice 1.0\",  # a 'pretty' name for the training dataset\n",
    "    \"dataset_args\": \"config: se, split: test\",\n",
    "    \"language\": \"ro\",\n",
    "    \"model_name\": \"Whisper Romanian\",  # a 'pretty' name for our model\n",
    "    \"finetuned_from\": \"openai/whisper-small\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training results can now be uploaded to the Hub. To do so, execute the `push_to_hub` command and save the preprocessor object we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38264e5820d245efb25a454f1056caaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb36b8937c8f4c03a5199d09e343d3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190a28ffccd84ec4b2eefa19fa9347f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1702208380.ArtanisPC.509.2:   0%|          | 0.00/16.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54db2b5fe594c87ae527ecba27bf397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d507aacf4ec24ca9b2904b5255b1d640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1702224301.ArtanisPC.509.3:   0%|          | 0.00/5.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e4e88c8cd14bb596cc59b2432a3a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Artanis1551/whisper_romanian/tree/main/'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
